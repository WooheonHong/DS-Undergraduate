{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 인공 신경망을 밑바닥부터 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"'path'에서 MNIST 데이터 불러오기\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                              f\"{kind}-labels.idx1-ubyte\")\n",
    "    images_path = os.path.join(path,\n",
    "                              f\"{kind}-images.idx3-ubyte\")\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                            dtype=np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\",\n",
    "                                              imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                            dtype=np.uint8).reshape(\n",
    "                            len(labels), 784)\n",
    "        images = ((images / 255) - 5) * 2\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행: 60000, 열: 784\n",
      "행: 10000, 열: 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('', kind='train')\n",
    "print(f\"행: {X_train.shape[0]}, 열: {X_train.shape[1]}\")\n",
    "X_test, y_test = load_mnist('', kind='t10k')\n",
    "print(f\"행: {X_test.shape[0]}, 열: {X_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=5,\n",
    "                      sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "    \n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5,\n",
    "                      sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = X_train[y_train == 7][i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('mnist_scaled.npz',\n",
    "                   X_train=X_train,\n",
    "                   y_train=y_train,\n",
    "                   X_test=X_test,\n",
    "                   y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist_scaled.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = [mnist[f] for \n",
    "                                   f in mnist.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "class NeuralNetMLP(object):\n",
    "    \"\"\"피드포워드 신경망 / 다층 퍼셉트론 분류기\n",
    "\n",
    "    매개변수\n",
    "\n",
    "    ------------\n",
    "    n_hidden : int (기본값: 30)\n",
    "        은닉 유닛 개수\n",
    "    l2 : float (기본값: 0.)\n",
    "        L2 규제의 람다 값\n",
    "        l2=0이면 규제 없음. (기본값)\n",
    "    epochs : int (기본값: 100)\n",
    "        훈련 세트를 반복할 횟수\n",
    "    eta : float (기본값: 0.001)\n",
    "        학습률\n",
    "    shuffle : bool (기본값: True)\n",
    "        에포크마다 훈련 세트를 섞을지 여부\n",
    "        True이면 데이터를 섞어 순서를 바꿉니다\n",
    "    minibatch_size : int (기본값: 1)\n",
    "        미니 배치의 훈련 샘플 개수\n",
    "    seed : int (기본값: None)\n",
    "        가중치와 데이터 셔플링을 위한 난수 초깃값\n",
    "\n",
    "    속성\n",
    "    -----------\n",
    "    eval_ : dict\n",
    "      훈련 에포크마다 비용, 훈련 정확도, 검증 정확도를 수집하기 위한 딕셔너리\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 l2=0., epochs=100, eta=0.001,\n",
    "                 shuffle=True, minibatch_size=1, seed=None):\n",
    "\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2 = l2\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.shuffle = shuffle\n",
    "        self.minibatch_size = minibatch_size\n",
    "\n",
    "    def _onehot(self, y, n_classes):\n",
    "        \"\"\"레이블을 원-핫 방식으로 인코딩합니다\n",
    "\n",
    "        매개변수\n",
    "        ------------\n",
    "        y : 배열, 크기 = [n_samples]\n",
    "            타깃 값.\n",
    "\n",
    "        반환값\n",
    "        -----------\n",
    "        onehot : 배열, 크기 = (n_samples, n_labels)\n",
    "\n",
    "        \"\"\"\n",
    "        onehot = np.zeros((n_classes, y.shape[0]))\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            onehot[val, idx] = 1.\n",
    "        return onehot.T\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"로지스틱 함수(시그모이드)를 계산합니다\"\"\"\n",
    "        return 1. / (1. + np.exp(-np.clip(z, -250, 250)))\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"정방향 계산을 수행합니다\"\"\"\n",
    "\n",
    "        # 단계 1: 은닉층의 최종 입력\n",
    "        # [n_samples, n_features] dot [n_features, n_hidden]\n",
    "        # -> [n_samples, n_hidden]\n",
    "        z_h = np.dot(X, self.w_h) + self.b_h\n",
    "\n",
    "        # 단계 2: 은닉층의 활성화 출력\n",
    "        a_h = self._sigmoid(z_h)\n",
    "\n",
    "        # 단계 3: 출력층의 최종 입력\n",
    "        # [n_samples, n_hidden] dot [n_hidden, n_classlabels]\n",
    "        # -> [n_samples, n_classlabels]\n",
    "\n",
    "        z_out = np.dot(a_h, self.w_out) + self.b_out\n",
    "\n",
    "        # 단계 4: 출력층의 활성화 출력\n",
    "        a_out = self._sigmoid(z_out)\n",
    "\n",
    "        return z_h, a_h, z_out, a_out\n",
    "\n",
    "    def _compute_cost(self, y_enc, output):\n",
    "        \"\"\"비용 함수를 계산합니다\n",
    "\n",
    "        매개변수\n",
    "        ----------\n",
    "        y_enc : 배열, 크기 = (n_samples, n_labels)\n",
    "            원-핫 인코딩된 클래스 레이블\n",
    "        output : 배열, 크기 = [n_samples, n_output_units]\n",
    "            출력층의 활성화 출력 (정방향 계산)\n",
    "\n",
    "        반환값\n",
    "        ---------\n",
    "        cost : float\n",
    "            규제가 포함된 비용\n",
    "\n",
    "        \"\"\"\n",
    "        L2_term = (self.l2 *\n",
    "                   (np.sum(self.w_h ** 2.) +\n",
    "                    np.sum(self.w_out ** 2.)))\n",
    "\n",
    "        term1 = -y_enc * (np.log(output))\n",
    "        term2 = (1. - y_enc) * np.log(1. - output)\n",
    "        cost = np.sum(term1 - term2) + L2_term\n",
    "        \n",
    "        # 다른 데이터셋에서는 극단적인 (0 또는 1에 가까운) 활성화 값이 나올 수 있습니다.\n",
    "        # 파이썬과 넘파이의 수치 연산이 불안정하기 때문에 \"ZeroDivisionError\"가 발생할 수 있습니다.\n",
    "        # 즉, log(0)을 평가하는 경우입니다.\n",
    "        # 이 문제를 해결하기 위해 로그 함수에 전달되는 활성화 값에 작은 상수를 더합니다.\n",
    "        #\n",
    "        # 예를 들어:\n",
    "        #\n",
    "        # term1 = -y_enc * (np.log(output + 1e-5))\n",
    "        # term2 = (1. - y_enc) * np.log(1. - output + 1e-5)\n",
    "        \n",
    "        return cost\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"클래스 레이블을 예측합니다\n",
    "\n",
    "        매개변수\n",
    "        -----------\n",
    "        X : 배열, 크기 = [n_samples, n_features]\n",
    "            원본 특성의 입력층\n",
    "\n",
    "        반환값:\n",
    "        ----------\n",
    "        y_pred : 배열, 크기 = [n_samples]\n",
    "            예측된 클래스 레이블\n",
    "\n",
    "        \"\"\"\n",
    "        z_h, a_h, z_out, a_out = self._forward(X)\n",
    "        y_pred = np.argmax(z_out, axis=1)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\"훈련 데이터에서 가중치를 학습합니다\n",
    "\n",
    "        매개변수\n",
    "        -----------\n",
    "        X_train : 배열, 크기 = [n_samples, n_features]\n",
    "            원본 특성의 입력층\n",
    "        y_train : 배열, 크기 = [n_samples]\n",
    "            타깃 클래스 레이블\n",
    "        X_valid : 배열, 크기 = [n_samples, n_features]\n",
    "            훈련하는 동안 검증에 사용할 샘플 특성\n",
    "        y_valid : 배열, 크기 = [n_samples]\n",
    "            훈련하는 동안 검증에 사용할 샘플 레이블\n",
    "\n",
    "        반환값:\n",
    "        ----------\n",
    "        self\n",
    "\n",
    "        \"\"\"\n",
    "        n_output = np.unique(y_train).shape[0]  # number of class labels\n",
    "        n_features = X_train.shape[1]\n",
    "\n",
    "        ########################\n",
    "        # 가중치 초기화\n",
    "        ########################\n",
    "\n",
    "        # 입력층 -> 은닉층 사이의 가중치\n",
    "        self.b_h = np.zeros(self.n_hidden)\n",
    "        self.w_h = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                      size=(n_features, self.n_hidden))\n",
    "\n",
    "        # 은닉층 -> 출력층 사이의 가중치\n",
    "        self.b_out = np.zeros(n_output)\n",
    "        self.w_out = self.random.normal(loc=0.0, scale=0.1,\n",
    "                                        size=(self.n_hidden, n_output))\n",
    "\n",
    "        epoch_strlen = len(str(self.epochs))  # 출력 포맷을 위해\n",
    "        self.eval_ = {'cost': [], 'train_acc': [], 'valid_acc': []}\n",
    "\n",
    "        y_train_enc = self._onehot(y_train, n_output)\n",
    "\n",
    "        # 훈련 에포크를 반복합니다\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            # 미니 배치로 반복합니다\n",
    "            indices = np.arange(X_train.shape[0])\n",
    "\n",
    "            if self.shuffle:\n",
    "                self.random.shuffle(indices)\n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size +\n",
    "                                   1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "\n",
    "                # 정방향 계산\n",
    "                z_h, a_h, z_out, a_out = self._forward(X_train[batch_idx])\n",
    "\n",
    "                ##################\n",
    "                # 역전파\n",
    "                ##################\n",
    "\n",
    "                # [n_samples, n_classlabels]\n",
    "                sigma_out = a_out - y_train_enc[batch_idx]\n",
    "\n",
    "                # [n_samples, n_hidden]\n",
    "                sigmoid_derivative_h = a_h * (1. - a_h)\n",
    "\n",
    "                # [n_samples, n_classlabels] dot [n_classlabels, n_hidden]\n",
    "                # -> [n_samples, n_hidden]\n",
    "                sigma_h = (np.dot(sigma_out, self.w_out.T) *\n",
    "                           sigmoid_derivative_h)\n",
    "\n",
    "                # [n_features, n_samples] dot [n_samples, n_hidden]\n",
    "                # -> [n_features, n_hidden]\n",
    "                grad_w_h = np.dot(X_train[batch_idx].T, sigma_h)\n",
    "                grad_b_h = np.sum(sigma_h, axis=0)\n",
    "\n",
    "                # [n_hidden, n_samples] dot [n_samples, n_classlabels]\n",
    "                # -> [n_hidden, n_classlabels]\n",
    "                grad_w_out = np.dot(a_h.T, sigma_out)\n",
    "                grad_b_out = np.sum(sigma_out, axis=0)\n",
    "\n",
    "                # 규제와 가중치 업데이트\n",
    "                delta_w_h = (grad_w_h + self.l2*self.w_h)\n",
    "                delta_b_h = grad_b_h # 편향은 규제하지 않습니다\n",
    "                self.w_h -= self.eta * delta_w_h\n",
    "                self.b_h -= self.eta * delta_b_h\n",
    "\n",
    "                delta_w_out = (grad_w_out + self.l2*self.w_out)\n",
    "                delta_b_out = grad_b_out  # 편향은 규제하지 않습니다\n",
    "                self.w_out -= self.eta * delta_w_out\n",
    "                self.b_out -= self.eta * delta_b_out\n",
    "\n",
    "            #############\n",
    "            # 평가\n",
    "            #############\n",
    "\n",
    "            # 훈련하는 동안 에포크마다 평가합니다\n",
    "            z_h, a_h, z_out, a_out = self._forward(X_train)\n",
    "            \n",
    "            cost = self._compute_cost(y_enc=y_train_enc,\n",
    "                                      output=a_out)\n",
    "\n",
    "            y_train_pred = self.predict(X_train)\n",
    "            y_valid_pred = self.predict(X_valid)\n",
    "\n",
    "            train_acc = ((np.sum(y_train == y_train_pred)).astype(np.float) /\n",
    "                         X_train.shape[0])\n",
    "            valid_acc = ((np.sum(y_valid == y_valid_pred)).astype(np.float) /\n",
    "                         X_valid.shape[0])\n",
    "\n",
    "            sys.stderr.write('\\r%0*d/%d | 비용: %.2f '\n",
    "                             '| 훈련/검증 정확도: %.2f%%/%.2f%% ' %\n",
    "                             (epoch_strlen, i+1, self.epochs, cost,\n",
    "                              train_acc*100, valid_acc*100))\n",
    "            sys.stderr.flush()\n",
    "\n",
    "            self.eval_['cost'].append(cost)\n",
    "            self.eval_['train_acc'].append(train_acc)\n",
    "            self.eval_['valid_acc'].append(valid_acc)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetMLP(n_hidden=100,\n",
    "                 l2=0.01,\n",
    "                 epochs=200,\n",
    "                 eta=0.0005,\n",
    "                 minibatch_size=100,\n",
    "                 shuffle=True,\n",
    "                 seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "060/200 | 비용: 9348.29 | 훈련/검증 정확도: 98.14%/97.30%  "
     ]
    }
   ],
   "source": [
    "nn.fit(X_train=X_train_centered[:55000],\n",
    "      y_train=y_train[:55000],\n",
    "      X_valid=X_train_centered[55000:],\n",
    "      y_valid=y_train[55000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로를 사용하여 신경망 훈련\n",
    "\n",
    "## 고성능 머신 러닝 라이브러리 텐서플로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 크기:  (3, 2, 3)\n",
      "크기가 변경된 입력:\n",
      " [[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]]\n",
      "열의 합:\n",
      " [18 21 24 27 30 33]\n",
      "열의 평균:\n",
      "  [ 6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_array = np.arange(18).reshape(3, 2, 3)\n",
    "\n",
    "x2 = tf.reshape(x_array, shape=(-1, 6))\n",
    "\n",
    "## 각 열의 합\n",
    "xsum = tf.reduce_sum(x2, axis=0)\n",
    "\n",
    "## 각 열의 평균\n",
    "xmean = tf.reduce_mean(x2, axis=0)\n",
    "\n",
    "print('입력 크기: ', x_array.shape)\n",
    "print('크기가 변경된 입력:\\n', x2.numpy())\n",
    "print('열의 합:\\n', xsum.numpy())\n",
    "print('열의 평균:\\n ', xmean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros(shape=1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape([1, 2, 3], [-1]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[context manager알아보기](https://ddanggle.gitbooks.io/interpy-kr/content/ch24-context-manager.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfLinreg(object):\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        ## 가중치와 절편을 정의합니다\n",
    "        self.w = tf.Variable(tf.zeros(shape=(1)))\n",
    "        self.b = tf.Variable(tf.zeros(shape=(1)))\n",
    "        ## 경사 하강법 옵티마이저를 설정합니다\n",
    "        self.optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "        \n",
    "    def fit(self, X, y, num_epochs=10):\n",
    "        training_cost = []\n",
    "        for step in range(num_epochs):\n",
    "        ## 자동 미분을 위해 연산 과정을 기록합니다\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_net = self.w * X + self.b\n",
    "                z_net = tf.reshape(z_net, [-1])\n",
    "                sqr_errors = tf.square(y - z_net)\n",
    "                mean_cost = tf.reduce_mean(sqr_errors)\n",
    "            ## 비용 함수에 대한 가중치의 그래디언트를 계산합니다\n",
    "            grads = tape.gradient(mean_cost, [self.w, self.b])\n",
    "            ## 옵티마이저에 그래디언트를 반영합니다\n",
    "            self.optimizer.apply_gradients(zip(grads, [self.w, self.b]))\n",
    "            ## 비용 함수의 값을 저장합니다\n",
    "            training_costs.append(mean_cost.numpy())\n",
    "        return training_costs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.w * X + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras API로 다층 신경망 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = np.load('mnist_scaled.npz')\n",
    "X_train, y_train, X_test, y_test = [mnist[f] for f in mnist.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (10000,)\n"
     ]
    }
   ],
   "source": [
    "mean_vals = np.mean(X_train, axis=0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals) / std_val\n",
    "X_test_centered = (X_test - mean_vals) / std_val\n",
    "\n",
    "del X_train, X_test\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_test_centered, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=X_train_centered.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=50,\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1],\n",
    "        input_dim=50,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 42,310\n",
      "Trainable params: 42,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=.9)\n",
    "\n",
    "model.compile(optimizer=sgd_optimizer,\n",
    "             loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 3s 56us/sample - loss: 0.7409 - val_loss: 0.3696\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.3756 - val_loss: 0.2788\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.3065 - val_loss: 0.2417\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.2687 - val_loss: 0.2175\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.2429 - val_loss: 0.2001\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.2231 - val_loss: 0.1870\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.2070 - val_loss: 0.1770\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.1935 - val_loss: 0.1673\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.1817 - val_loss: 0.1611\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1715 - val_loss: 0.1546\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1623 - val_loss: 0.1489\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 0.1540 - val_loss: 0.1447\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1469 - val_loss: 0.1399\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1402 - val_loss: 0.1364\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 2s 35us/sample - loss: 0.1341 - val_loss: 0.1341\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1286 - val_loss: 0.1306\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.1234 - val_loss: 0.1279\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 0.1187 - val_loss: 0.1261\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.1141 - val_loss: 0.1237\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.1100 - val_loss: 0.1218\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1060 - val_loss: 0.1206\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.1023 - val_loss: 0.1192\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0988 - val_loss: 0.1177\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0953 - val_loss: 0.1169\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0922 - val_loss: 0.1162\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0891 - val_loss: 0.1157\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0862 - val_loss: 0.1134\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0835 - val_loss: 0.1141\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0807 - val_loss: 0.1132\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0783 - val_loss: 0.1136\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 2s 36us/sample - loss: 0.0758 - val_loss: 0.1131\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0733 - val_loss: 0.1120\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0711 - val_loss: 0.1116\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0690 - val_loss: 0.1122\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0668 - val_loss: 0.1126\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 2s 40us/sample - loss: 0.0649 - val_loss: 0.1122\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0629 - val_loss: 0.1117\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 2s 39us/sample - loss: 0.0610 - val_loss: 0.1114\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0593 - val_loss: 0.1115\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0575 - val_loss: 0.1119\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0558 - val_loss: 0.1118\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0542 - val_loss: 0.1120\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 0.0526 - val_loss: 0.1113\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 2s 38us/sample - loss: 0.0511 - val_loss: 0.1121\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0496 - val_loss: 0.1119\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 0.0483 - val_loss: 0.1123\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 2s 41us/sample - loss: 0.0470 - val_loss: 0.1127\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0456 - val_loss: 0.1128\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0444 - val_loss: 0.1128\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 2s 37us/sample - loss: 0.0431 - val_loss: 0.1133\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_centered, y_train_onehot,\n",
    "                   batch_size=64, epochs=50,\n",
    "                   verbose=1,\n",
    "                   validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "print(y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 정확도: 99.00\n",
      "테스트 정확도: 95.97\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose=0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "print(f\"훈련 정확도: {train_acc*100:.2f}\")\n",
    "y_test_pred = model.predict_classes(X_test_centered,\n",
    "                                   verbose=0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "print(f\"테스트 정확도: {test_acc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
